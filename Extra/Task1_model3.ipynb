{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnH2Zi1Vj9h4",
        "outputId": "a6559f7c-b434-49d6-dfb1-4e1cc530bb9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8zHunoFcj8Zm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "import shutil\n",
        "# util function\n",
        "def create_or_clear_folder(folder_path):\n",
        "    # Check whether the folder exists\n",
        "    if os.path.exists(folder_path):\n",
        "        # If the folder exists, delete it and recreate it\n",
        "        shutil.rmtree(folder_path)\n",
        "        os.makedirs(folder_path)\n",
        "    else:\n",
        "        # If the folder does not exist, create it\n",
        "        os.makedirs(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/drive/MyDrive/ACDS/Selected_Storms_curated\"\n"
      ],
      "metadata": {
        "id": "Bf6TLK2akP8f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "Use two-dimensional lists to store image information"
      ],
      "metadata": {
        "id": "OHxb3WlGk8u7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo7vmR1Ij8Zm",
        "outputId": "9f3120bd-495b-4667-d5f0-99f9b77375e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hig', 'gme', 'woc', 'blq', 'kqu', 'wsy', 'ipa', 'ztb', 'gkf', 'qpq', 'pjj', 'rml', 'xjo', 'vxf', 'fgi', 'gic', 'fna', 'ing', 'yfn', 'ywf', 'mtw', 'eoi', 'sxb', 'vye', 'zny', 'psz', 'pvj', 'dzw', 'ojv', 'bkh']\n",
            "hig\n",
            "gme\n",
            "woc\n",
            "blq\n",
            "kqu\n",
            "wsy\n",
            "ipa\n",
            "ztb\n",
            "gkf\n",
            "qpq\n",
            "pjj\n",
            "rml\n",
            "xjo\n",
            "vxf\n",
            "fgi\n",
            "gic\n",
            "fna\n",
            "ing\n",
            "yfn\n",
            "ywf\n",
            "mtw\n",
            "eoi\n",
            "sxb\n",
            "vye\n",
            "zny\n",
            "psz\n",
            "pvj\n",
            "dzw\n",
            "ojv\n",
            "bkh\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "\n",
        "samples = []\n",
        "\n",
        "subfolder = os.listdir(data_folder)\n",
        "print(subfolder)\n",
        "for fol in subfolder:\n",
        "    print(fol)\n",
        "    now_sample = []\n",
        "    wind_folder = os.path.join(data_folder, fol)\n",
        "    useful_data = list(set([f[:7] for f in os.listdir(wind_folder) if f.startswith(fol)]))\n",
        "    for name in useful_data:\n",
        "        image_path = os.path.join(wind_folder, name+'.jpg')\n",
        "        json_path = os.path.join(wind_folder, name+'_features.json')\n",
        "        time = eval(json.load(open(json_path,'r'))['relative_time'])\n",
        "        now_sample.append((image_path, time))\n",
        "    now_sample.sort(key=lambda x: x[1])\n",
        "    samples.append(now_sample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVmBvwqeoB0P",
        "outputId": "84ed251e-c71e-4de8-e846-d0640631bcd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Embedding\n",
        "After EDA analysis, it was noticed that the sample number and the standard deviation and precision difference of the time interval between different types of storms were different, so the means of time coding was adopted here (considering the time limit of the overall development process, a relatively simple way was chosen)."
      ],
      "metadata": {
        "id": "jwz_7JNUgaZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zOTFfYrMFRTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The code processes image sequences with the following steps:\n",
        "\n",
        "1. **Image Sequence Extraction**: Sequentially selects images from a specified index to form a complete sequence, including historical images and future images for prediction. The length of the historical image sequence is defined by `self.sequence_length`, and the length of the future image sequence for prediction is defined by `self.pre_len`.\n",
        "2. **Image Loading**: Loads images from a pre-processed list of image data to avoid repetitive disk reads, enhancing efficiency.\n",
        "3. **Time ID Calculation**: Calculates a time ID for each image, indicating the time difference from the first image in the sequence, to capture the temporal dimension.\n",
        "4. **Sequence Division**: Divides the complete image sequence into two parts: a sequence of historical images for model input and a sequence of future images for prediction."
      ],
      "metadata": {
        "id": "WMtYJc8KP8BM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ovG0VMxkj8Zn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((366, 366)),\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  #\n",
        "])\n",
        "\n",
        "class ImageSequenceDataset(Dataset):\n",
        "    def __init__(self, data, sequence_length=6, pre_len=3, transform=None) -> None:\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.sequence_length = sequence_length\n",
        "        self.pre_len = pre_len\n",
        "        self.transform = transform\n",
        "\n",
        "        self.data_id = []\n",
        "        for i, d in enumerate(self.data):\n",
        "            for j in range(len(d)-sequence_length-pre_len+1):\n",
        "                self.data_id.append((i, j))\n",
        "\n",
        "        self.img_data = []\n",
        "        for wd in tqdm(self.data, desc='Processing Data'):\n",
        "            now_img = []\n",
        "            for image_path, time in wd:\n",
        "                image = Image.open(image_path).convert('L')\n",
        "\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "                now_img.append(image)\n",
        "            self.img_data.append(now_img)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        wind_id, sample_id = self.data_id[idx]\n",
        "        time_start = self.data[wind_id][sample_id][1] #Start time time ➗1000 is the time embedding id\n",
        "\n",
        "        images = []\n",
        "        times = []\n",
        "\n",
        "        for i in range(sample_id, sample_id+self.sequence_length+self.pre_len):\n",
        "            image_path, time = self.data[wind_id][i]\n",
        "\n",
        "            image = self.img_data[wind_id][i]\n",
        "            images.append(image)\n",
        "            time_id = (time-time_start)//1000\n",
        "            if time_id > 49:time_id = 49\n",
        "            elif time_id <0:time_id = 0\n",
        "\n",
        "\n",
        "            times.append(time_id)\n",
        "            time_start = time\n",
        "\n",
        "        sequence_images = images[:self.sequence_length]\n",
        "        prediction_images = images[self.sequence_length:]\n",
        "\n",
        "        sequence_images = torch.stack(sequence_images)\n",
        "        prediction_images = torch.stack(prediction_images)\n",
        "        times = torch.LongTensor(times)\n",
        "\n",
        "        return sequence_images, prediction_images, times"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add for some tests"
      ],
      "metadata": {
        "id": "Xx0aXxUxo37x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means using GME to simulate an unknown storm forecast. Measure our model by setting GME as a test set and seeing how the model performs on it"
      ],
      "metadata": {
        "id": "bAhLuqLp2NoQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUtZjkC1j8Zn",
        "outputId": "f2931d5e-8dcf-4d05-c2b1-200a2db86d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test wind - bkh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Data: 100%|██████████| 29/29 [00:45<00:00,  1.58s/it]\n",
            "Processing Data: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n"
          ]
        }
      ],
      "source": [
        "# print(f\"Test wind - {subfolder[-1]}\")\n",
        "# train_dataset = ImageSequenceDataset(samples[:-1], transform=transform)\n",
        "# test_dataset = ImageSequenceDataset(samples[-1:], transform=transform)\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset,\n",
        "#                         batch_size=8,\n",
        "#                         shuffle=True)\n",
        "\n",
        "# test_dataloader = DataLoader(train_dataset,\n",
        "#                         batch_size=8,\n",
        "#                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = [sample for i, sample in enumerate(samples) if i != 1]  # no 'gme'\n",
        "test_samples = [samples[1]]  # only gme"
      ],
      "metadata": {
        "id": "gc6SCh-xuocA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLR76DIHwFR9",
        "outputId": "575dac4e-2713-420b-839a-7bb463ef9e0c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_000.jpg', 0),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_001.jpg',\n",
              "   1800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_002.jpg',\n",
              "   3600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_003.jpg',\n",
              "   5400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_004.jpg',\n",
              "   7200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_005.jpg',\n",
              "   10801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_006.jpg',\n",
              "   12602),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_007.jpg',\n",
              "   14401),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_008.jpg',\n",
              "   16201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_009.jpg',\n",
              "   18002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_010.jpg',\n",
              "   21601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_011.jpg',\n",
              "   23402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_012.jpg',\n",
              "   25201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_013.jpg',\n",
              "   27002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_014.jpg',\n",
              "   28801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_015.jpg',\n",
              "   32402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_016.jpg',\n",
              "   34201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_017.jpg',\n",
              "   36002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_018.jpg',\n",
              "   37801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_019.jpg',\n",
              "   39601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_020.jpg',\n",
              "   43201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_021.jpg',\n",
              "   45001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_022.jpg',\n",
              "   46802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_023.jpg',\n",
              "   48601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_024.jpg',\n",
              "   50402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_025.jpg',\n",
              "   54000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_026.jpg',\n",
              "   55800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_027.jpg',\n",
              "   57600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_028.jpg',\n",
              "   59400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_029.jpg',\n",
              "   61200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_030.jpg',\n",
              "   64802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_031.jpg',\n",
              "   66600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_032.jpg',\n",
              "   68401),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_033.jpg',\n",
              "   70200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_034.jpg',\n",
              "   72000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_035.jpg',\n",
              "   75600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_036.jpg',\n",
              "   77400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_037.jpg',\n",
              "   79200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_038.jpg',\n",
              "   80999),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_039.jpg',\n",
              "   82800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_040.jpg',\n",
              "   86399),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_041.jpg',\n",
              "   88200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_042.jpg',\n",
              "   90000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_043.jpg',\n",
              "   91800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_044.jpg',\n",
              "   93600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_045.jpg',\n",
              "   97201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_046.jpg',\n",
              "   99002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_047.jpg',\n",
              "   100801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_048.jpg',\n",
              "   102601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_049.jpg',\n",
              "   104402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_050.jpg',\n",
              "   108002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_051.jpg',\n",
              "   109801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_052.jpg',\n",
              "   111601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_053.jpg',\n",
              "   113402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_054.jpg',\n",
              "   115201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_055.jpg',\n",
              "   118801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_056.jpg',\n",
              "   120601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_057.jpg',\n",
              "   122402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_058.jpg',\n",
              "   124201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_059.jpg',\n",
              "   126001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_060.jpg',\n",
              "   129601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_061.jpg',\n",
              "   131402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_062.jpg',\n",
              "   133201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_063.jpg',\n",
              "   135001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_064.jpg',\n",
              "   136802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_065.jpg',\n",
              "   140400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_066.jpg',\n",
              "   142199),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_067.jpg',\n",
              "   144000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_068.jpg',\n",
              "   145800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_069.jpg',\n",
              "   147599),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_070.jpg',\n",
              "   151200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_071.jpg',\n",
              "   153000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_072.jpg',\n",
              "   154802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_073.jpg',\n",
              "   156600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_074.jpg',\n",
              "   158401),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_075.jpg',\n",
              "   162000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_076.jpg',\n",
              "   163800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_077.jpg',\n",
              "   165600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_078.jpg',\n",
              "   167400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_079.jpg',\n",
              "   169200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_080.jpg',\n",
              "   172801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_081.jpg',\n",
              "   174601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_082.jpg',\n",
              "   176399),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_083.jpg',\n",
              "   178200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_084.jpg',\n",
              "   180000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_085.jpg',\n",
              "   183601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_086.jpg',\n",
              "   185402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_087.jpg',\n",
              "   187201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_088.jpg',\n",
              "   189002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_089.jpg',\n",
              "   190801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_090.jpg',\n",
              "   194402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_091.jpg',\n",
              "   196201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_092.jpg',\n",
              "   198002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_093.jpg',\n",
              "   199801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_094.jpg',\n",
              "   201601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_095.jpg',\n",
              "   205201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_096.jpg',\n",
              "   207003),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_097.jpg',\n",
              "   208801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_098.jpg',\n",
              "   210601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_099.jpg',\n",
              "   212402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_100.jpg',\n",
              "   216001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_101.jpg',\n",
              "   217802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_102.jpg',\n",
              "   219601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_103.jpg',\n",
              "   221401),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_104.jpg',\n",
              "   223201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_105.jpg',\n",
              "   226800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_106.jpg',\n",
              "   228600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_107.jpg',\n",
              "   230400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_108.jpg',\n",
              "   232202),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_109.jpg',\n",
              "   234001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_110.jpg',\n",
              "   237599),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_111.jpg',\n",
              "   239400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_112.jpg',\n",
              "   241200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_113.jpg',\n",
              "   242999),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_114.jpg',\n",
              "   244801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_115.jpg',\n",
              "   248400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_116.jpg',\n",
              "   250200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_117.jpg',\n",
              "   251999),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_118.jpg',\n",
              "   253800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_119.jpg',\n",
              "   255600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_120.jpg',\n",
              "   259200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_121.jpg',\n",
              "   261002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_122.jpg',\n",
              "   262800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_123.jpg',\n",
              "   264600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_124.jpg',\n",
              "   266399),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_125.jpg',\n",
              "   270002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_126.jpg',\n",
              "   271801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_127.jpg',\n",
              "   273601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_128.jpg',\n",
              "   275402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_129.jpg',\n",
              "   277201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_130.jpg',\n",
              "   280801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_131.jpg',\n",
              "   282601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_132.jpg',\n",
              "   284402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_133.jpg',\n",
              "   286201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_134.jpg',\n",
              "   288001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_135.jpg',\n",
              "   291601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_136.jpg',\n",
              "   293402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_137.jpg',\n",
              "   295201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_138.jpg',\n",
              "   297001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_139.jpg',\n",
              "   298802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_140.jpg',\n",
              "   302401),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_141.jpg',\n",
              "   304201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_142.jpg',\n",
              "   306001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_143.jpg',\n",
              "   307802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_144.jpg',\n",
              "   309601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_145.jpg',\n",
              "   313200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_146.jpg',\n",
              "   315001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_147.jpg',\n",
              "   316800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_148.jpg',\n",
              "   318600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_149.jpg',\n",
              "   320401),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_150.jpg',\n",
              "   324001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_151.jpg',\n",
              "   325800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_152.jpg',\n",
              "   327600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_153.jpg',\n",
              "   329400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_154.jpg',\n",
              "   331202),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_155.jpg',\n",
              "   334800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_156.jpg',\n",
              "   336600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_157.jpg',\n",
              "   338400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_158.jpg',\n",
              "   340200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_159.jpg',\n",
              "   342000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_160.jpg',\n",
              "   345600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_161.jpg',\n",
              "   347399),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_162.jpg',\n",
              "   349200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_163.jpg',\n",
              "   351001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_164.jpg',\n",
              "   352800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_165.jpg',\n",
              "   356402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_166.jpg',\n",
              "   358201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_167.jpg',\n",
              "   360002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_168.jpg',\n",
              "   361801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_169.jpg',\n",
              "   363601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_170.jpg',\n",
              "   367201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_171.jpg',\n",
              "   369002),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_172.jpg',\n",
              "   370801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_173.jpg',\n",
              "   372601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_174.jpg',\n",
              "   374402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_175.jpg',\n",
              "   378001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_176.jpg',\n",
              "   379802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_177.jpg',\n",
              "   381601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_178.jpg',\n",
              "   383402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_179.jpg',\n",
              "   385201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_180.jpg',\n",
              "   388802),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_181.jpg',\n",
              "   390601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_182.jpg',\n",
              "   392401),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_183.jpg',\n",
              "   394201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_184.jpg',\n",
              "   396001),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_185.jpg',\n",
              "   399600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_186.jpg',\n",
              "   401400),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_187.jpg',\n",
              "   403202),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_188.jpg',\n",
              "   405000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_189.jpg',\n",
              "   406800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_190.jpg',\n",
              "   410401),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_191.jpg',\n",
              "   412202),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_192.jpg',\n",
              "   414000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_193.jpg',\n",
              "   415800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_194.jpg',\n",
              "   417600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_195.jpg',\n",
              "   421200),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_196.jpg',\n",
              "   423000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_197.jpg',\n",
              "   424801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_198.jpg',\n",
              "   426600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_199.jpg',\n",
              "   428399),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_200.jpg',\n",
              "   432000),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_201.jpg',\n",
              "   433800),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_202.jpg',\n",
              "   435600),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_203.jpg',\n",
              "   439202),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_204.jpg',\n",
              "   442801),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_205.jpg',\n",
              "   444601),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_206.jpg',\n",
              "   446402),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_207.jpg',\n",
              "   448201),\n",
              "  ('/content/drive/MyDrive/ACDS/Selected_Storms_curated/gme/gme_208.jpg',\n",
              "   450001)]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "set bs = 8"
      ],
      "metadata": {
        "id": "sRWa4e5bw4fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test wind - {subfolder[1]}\")\n",
        "train_dataset = ImageSequenceDataset(train_samples, transform=transform)\n",
        "test_dataset = ImageSequenceDataset(test_samples, transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                        batch_size=8,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                        batch_size=8,\n",
        "                        shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GONlCTNEwmUD",
        "outputId": "1fc83c1e-7fb8-4385-c0b8-d4781ed70f60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test wind - gme\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Data: 100%|██████████| 29/29 [00:47<00:00,  1.65s/it]\n",
            "Processing Data: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "last_batch_data = None\n",
        "\n",
        "# Itering test_dataLoader\n",
        "for batch_data in test_dataloader:\n",
        "    last_batch_data = batch_data  # Update the data for the last batch\n",
        "\n",
        "if last_batch_data is not None:\n",
        "    sequence_images, prediction_images, times = last_batch_data\n",
        "    print(f\"Sequence images shape: {sequence_images.shape}\")\n",
        "    print(f\"Prediction images shape: {prediction_images.shape}\")\n",
        "    print(f\"Times shape: {times.shape}\")\n",
        "else:\n",
        "    print(\"No data in the DataLoader\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FalMrXPtpMb_",
        "outputId": "f319a3de-fa5b-42a9-9056-a20792e756cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence images shape: torch.Size([1, 6, 1, 366, 366])\n",
            "Prediction images shape: torch.Size([1, 3, 1, 366, 366])\n",
            "Times shape: torch.Size([1, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `sequence_images`: A tensor of sequence images with the shape `[batch_size, sequence_length, channels, height, width]`.\n",
        "- `prediction_images`: A tensor of prediction images with the shape `[batch_size, pre_len, channels, height, width]`, where `pre_len` is the number of images to be predicted.\n",
        "- `times`: Timestamp information with the shape `[batch_size, sequence_length + pre_len]`."
      ],
      "metadata": {
        "id": "mkROIqWAra5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "Let's move on to the definition of the model: this is based on a very standard ConvLSTM schema change, with some differences from our group's second implementation, CNN_LSTM, which is a more integrated approach that deals with both spatial and temporal information at each time step. CNN_LSTM is a two-stage approach, processing spatial information first, and then processing time information."
      ],
      "metadata": {
        "id": "g8lCGJSe2dOs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GV11QzhEj8Zn"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
        "        \"\"\"\n",
        "        Initialize ConvLSTM cell.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim: int\n",
        "            Number of channels of input tensor.\n",
        "        hidden_dim: int\n",
        "            Number of channels of hidden state.\n",
        "        kernel_size: (int, int)\n",
        "            Size of the convolutional kernel.\n",
        "        bias: bool\n",
        "            Whether or not to add the bias.\n",
        "        \"\"\"\n",
        "\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = kernel_size // 2, kernel_size // 2\n",
        "        self.bias = bias\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
        "\n",
        "        combined_conv = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_hidden(self, batch_size, image_size):\n",
        "        height, width = image_size\n",
        "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
        "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
        "\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters:\n",
        "        input_dim: Number of channels in input\n",
        "        hidden_dim: Number of hidden channels\n",
        "        kernel_size: Size of kernel in convolutions\n",
        "        num_layers: Number of LSTM layers stacked on each other\n",
        "        batch_first: Whether or not dimension 0 is the batch or not\n",
        "        bias: Bias or no bias in Convolution\n",
        "        return_all_layers: Return the list of computations for all layers\n",
        "        Note: Will do same padding.\n",
        "\n",
        "    Input:\n",
        "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
        "    Output:\n",
        "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
        "            0 - layer_output_list is the list of lists of length T of each output\n",
        "            1 - last_state_list is the list of last states\n",
        "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
        "    Example:\n",
        "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
        "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
        "        >> _, last_states = convlstm(x)\n",
        "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=1, hidden_dim=[16, 8, 1], kernel_size=[3,3,3], num_layers=3,\n",
        "                 batch_first=True, bias=True, return_all_layers=True):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
        "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
        "            raise ValueError('Inconsistent list length.')\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        self.bias = bias\n",
        "        self.return_all_layers = return_all_layers\n",
        "\n",
        "        # Add and initialize parameters\n",
        "        self.time_embedding = nn.Parameter(torch.zeros(50, 1, 366, 366), requires_grad=True)\n",
        "\n",
        "        cell_list = []\n",
        "        for i in range(0, self.num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
        "\n",
        "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
        "                                          hidden_dim=self.hidden_dim[i],\n",
        "                                          kernel_size=self.kernel_size[i],\n",
        "                                          bias=self.bias))\n",
        "\n",
        "        self.cell_list = nn.ModuleList(cell_list)\n",
        "\n",
        "    def forward(self, input_tensor, times, hidden_state=None):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor: todo\n",
        "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
        "        hidden_state: todo\n",
        "            None. todo implement stateful\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        last_state_list, layer_output\n",
        "        \"\"\"\n",
        "        if not self.batch_first:\n",
        "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
        "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        b, _, _, h, w = input_tensor.size()\n",
        "\n",
        "        # Implement stateful ConvLSTM\n",
        "        if hidden_state is not None:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            # Since the init is done in forward. Can send image size here\n",
        "            hidden_state = self._init_hidden(batch_size=b,\n",
        "                                             image_size=(h, w))\n",
        "\n",
        "        layer_output_list = []\n",
        "        last_state_list = []\n",
        "\n",
        "        seq_len = input_tensor.size(1)\n",
        "        cur_layer_input = input_tensor + self.time_embedding[times[:,:input_tensor.size(1)]]\n",
        "\n",
        "        for layer_idx in range(self.num_layers):\n",
        "\n",
        "            h, c = hidden_state[layer_idx]\n",
        "            output_inner = []\n",
        "            for t in range(seq_len):\n",
        "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
        "                                                 cur_state=[h, c])\n",
        "                output_inner.append(h)\n",
        "\n",
        "            layer_output = torch.stack(output_inner, dim=1)\n",
        "            cur_layer_input = layer_output\n",
        "\n",
        "            layer_output_list.append(layer_output)\n",
        "            last_state_list.append([h, c])\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            layer_output_list = layer_output_list[-1:]\n",
        "            last_state_list = last_state_list[-1:]\n",
        "\n",
        "        return layer_output_list, last_state_list\n",
        "\n",
        "    def _init_hidden(self, batch_size, image_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
        "        return init_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "t5PSWki7j8Zo"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 10\n",
        "model = ConvLSTM()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce8ZrTCw4-8Q",
        "outputId": "811ecb37-1c32-43f9-8f57-97bca08ddc5b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvLSTM(\n",
              "  (cell_list): ModuleList(\n",
              "    (0): ConvLSTMCell(\n",
              "      (conv): Conv2d(17, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (1): ConvLSTMCell(\n",
              "      (conv): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (2): ConvLSTMCell(\n",
              "      (conv): Conv2d(9, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 epochs with batch_size = 8:"
      ],
      "metadata": {
        "id": "iof5LMaF5py-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i-IEm8Jj8Zo",
        "outputId": "c4c38c65-2cb1-4bb0-84b7-30510eb40952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 1136/1136 [14:08<00:00,  1.34it/s, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 1: 0.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.0138]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 2: 0.0138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.0137]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 3: 0.0137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.0135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 4: 0.0135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.0132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 5: 0.0132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.013]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 6: 0.0130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.0129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 7: 0.0129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.0129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 8: 0.0129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.0128]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 9: 0.0128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 1136/1136 [12:33<00:00,  1.51it/s, loss=0.0128]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 10: 0.0128\n"
          ]
        }
      ],
      "source": [
        "best_epoch_loss = float('inf')\n",
        "all_loss = []\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    with tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\") as tepoch:\n",
        "        for i, (input_sequences, target_sequences, times) in tepoch:\n",
        "\n",
        "            input_sequences = input_sequences.to(device)\n",
        "            target_sequences = target_sequences.to(device)\n",
        "            times = times.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward propagation\n",
        "            layer_output_list, _ = model(input_sequences, times)\n",
        "            output_sequences = layer_output_list[-1][:,-target_sequences.size(1):]  # Take the output of the last layer\n",
        "\n",
        "            # calculate loss\n",
        "            loss = criterion(output_sequences, target_sequences)\n",
        "            epoch_loss += loss.item()\n",
        "            all_loss.append(loss.item())\n",
        "            # Backpropagation and Optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update progress bar\n",
        "            tepoch.set_postfix(loss=epoch_loss/(i+1))\n",
        "\n",
        "    average_epoch_loss = epoch_loss / len(train_dataloader)\n",
        "    print(f\"Average Loss for Epoch {epoch + 1}: {average_epoch_loss:.4f}\")\n",
        "\n",
        "    # Check if it is the best model\n",
        "    if average_epoch_loss < best_epoch_loss:\n",
        "        best_epoch_loss = average_epoch_loss\n",
        "        # save_model\n",
        "        torch.save(model.state_dict(), 'best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tdJIXVj1j8Zo",
        "outputId": "487634b7-b379-4ba4-96ba-2ea1c742b468"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_loss)\n",
        "plt.xlabel(\"Iter\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.grid(\"--\")\n",
        "plt.savefig(\"loss_curve.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oik1PYrkj8Zo",
        "outputId": "c756b786-9ff0-4eb1-d361-2feb5333e84c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When iterating through the test data loader (`test_dataloader`), the model generates predictions for each batch. If we set `'gme'` as the test set, the comparison between the model's predictions and the actual situation of each image depends on the following aspects:\n",
        "\n",
        "- **Batch Size**: `batch_size` determines the number of images processed by the model at each pass. If `batch_size` is set to 8, then 8 images will be processed simultaneously by the model in each iteration.\n",
        "\n",
        "- **Batch Processing**: For each batch, the model makes predictions for all the images within it, generating an output sequence. Subsequently, the code will draw input, target (real), predicted, and difference images for each image in that batch.\n",
        "\n",
        "- **Per-Image Processing**: Within each batch, the code processes each image individually through a loop (`for k in range(len(input_sequences)):`), generating and saving corresponding images for each."
      ],
      "metadata": {
        "id": "q6hXPF1BIfqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snGjbl4Zj8Zo",
        "outputId": "7f1197e3-8286-4930-8c72-5ebc1f069e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 24/26 [54:06<07:50, 235.15s/it]"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "all_inputs = []\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "create_or_clear_folder(os.path.join(\"TestImage\"))\n",
        "\n",
        "model.eval()\n",
        "with tqdm(enumerate(test_dataloader), total=len(test_dataloader)) as tepoch:\n",
        "    for j, (input_sequences, target_sequences, times) in tepoch:\n",
        "\n",
        "        input_sequences = input_sequences.to(device)\n",
        "        target_sequences = target_sequences.to(device)\n",
        "        times = times.to(device)\n",
        "\n",
        "        #\n",
        "        layer_output_list, _ = model(input_sequences, times)\n",
        "        output_sequences = layer_output_list[-1][:,-target_sequences.size(1):]  # Take the output of the last layer\n",
        "\n",
        "        for k in range(len(input_sequences)):\n",
        "            for i, img in enumerate(input_sequences[k].detach().cpu()):\n",
        "                img = img.clamp(0, 1)\n",
        "                img = TF.to_pil_image(img)\n",
        "                plt.subplot(3, 6, i+1)\n",
        "                plt.imshow(img, cmap='gray')\n",
        "                plt.axis('off')  # Do not display coordinate axes\n",
        "                plt.title(f'Input-{i+1}')\n",
        "\n",
        "            for i, img in enumerate(target_sequences[k].detach().cpu()):\n",
        "                img = img.clamp(0, 1)\n",
        "                img = TF.to_pil_image(img)\n",
        "                plt.subplot(3, 6, i+1+6)\n",
        "                plt.imshow(img, cmap='gray')\n",
        "                plt.axis('off')  # Do not display coordinate axes\n",
        "                plt.title(f'Target-{i+1}')\n",
        "\n",
        "            for i, img in enumerate(output_sequences[k].detach().cpu()):\n",
        "                img = img.clamp(0, 1)\n",
        "                img = TF.to_pil_image(img)\n",
        "                plt.subplot(3, 6, i+1+6+3)\n",
        "                plt.imshow(img, cmap='gray')\n",
        "                plt.axis('off')  # Do not display coordinate axes\n",
        "                plt.title(f'Prediction-{i+1}')\n",
        "            # Draw the difference between the target image and the predicted image\n",
        "            for i, (target_img, output_img) in enumerate(zip(target_sequences[k], output_sequences[k])):\n",
        "                # Calculated difference\n",
        "                diff = torch.abs(target_img - output_img)\n",
        "                diff = diff.clamp(0, 1)  # Make sure the difference is within a valid range\n",
        "                diff = TF.to_pil_image(diff)\n",
        "                # Draw a difference image\n",
        "                plt.subplot(3, 6, i+1+12)  # Adjust the position of the subgraph\n",
        "                plt.imshow(diff, cmap='gray')\n",
        "                plt.axis('off')\n",
        "                plt.title(f'Difference-{i+1}')\n",
        "\n",
        "            # Adjust the spacing of subgraphs\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Save or display the image\n",
        "            plt.savefig(os.path.join(\"TestImage\", f\"Sample-{k}-{j}.jpg\"))  # Save image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h3P5-cMFJkN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize cumulative difference and image count\n",
        "total_diff = 0\n",
        "total_images = 0\n",
        "\n",
        "model.eval()\n",
        "with tqdm(enumerate(test_dataloader), total=len(test_dataloader)) as tepoch:\n",
        "    for j, (input_sequences, target_sequences, times) in tepoch:\n",
        "        input_sequences = input_sequences.to(device)\n",
        "        target_sequences = target_sequences.to(device)\n",
        "        times = times.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        layer_output_list, _ = model(input_sequences, times)\n",
        "        output_sequences = layer_output_list[-1][:, -target_sequences.size(1):]  # Take the output of the last layer\n",
        "\n",
        "        for k in range(len(input_sequences)):\n",
        "            # (Code for generating and saving images)\n",
        "\n",
        "            # Calculate absolute difference and update total difference and image count\n",
        "            diff = torch.abs(target_sequences[k] - output_sequences[k])\n",
        "            total_diff += diff.sum().item()  # Update total difference\n",
        "            total_images += diff.numel()  # Update total number of pixels across all images\n",
        "\n",
        "# Calculate and print Mean Absolute Error (MAE) over all test images\n",
        "mae = total_diff / total_images\n",
        "print(f'Mean Absolute Error (MAE) over all test images: {mae:.4f}')\n"
      ],
      "metadata": {
        "id": "olu3ZUoDIKd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVqfRwsRj8Zp"
      },
      "outputs": [],
      "source": [
        "# Save the prediction pictures\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "subfolder = os.listdir(data_folder)\n",
        "create_or_clear_folder(\"Result\")\n",
        "for fol in subfolder:\n",
        "    now_sample = []\n",
        "    wind_folder = os.path.join(data_folder, fol)\n",
        "    useful_data = list(set([f[:7] for f in os.listdir(wind_folder) if f.startswith(fol)]))\n",
        "    for name in useful_data:\n",
        "        image_path = os.path.join(wind_folder, name+'.jpg')\n",
        "        json_path = os.path.join(wind_folder, name+'_features.json')\n",
        "        time = eval(json.load(open(json_path,'r'))['relative_time'])\n",
        "        now_sample.append((image_path, time))\n",
        "    now_sample.sort(key=lambda x: x[1])\n",
        "\n",
        "    inp_image = []\n",
        "    inp_time = []\n",
        "    time_start = now_sample[-6][1]\n",
        "    for imgpath, time in now_sample[-6:]:\n",
        "        image = Image.open(imgpath).convert('L')\n",
        "        image = transform(image)\n",
        "        inp_image.append(image)\n",
        "\n",
        "        time_id = (time-time_start)//1000\n",
        "        if time_id > 49:time_id = 49\n",
        "        elif time_id <0:time_id = 0\n",
        "        inp_time.append(time_id)\n",
        "        time_start = time\n",
        "    sequence_images = torch.stack(inp_image).to(device).unsqueeze(0)\n",
        "    times = torch.LongTensor(inp_time).to(device).unsqueeze(0)\n",
        "    layer_output_list, _ = model(sequence_images, times)\n",
        "    output_sequences = layer_output_list[-1][0,-3:].detach().cpu()  # 取最后一层的输出\n",
        "    create_or_clear_folder(os.path.join(\"Result\", fol))\n",
        "    for i, img in enumerate(output_sequences):\n",
        "        img = img.clamp(0, 1)\n",
        "\n",
        "        #\n",
        "        img = TF.to_pil_image(img)\n",
        "        # save images\n",
        "        img.save(os.path.join(\"Result\", fol, \"{}.jpg\".format(i+1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The memory usage of the colab session crashed, and the fault was rectified later"
      ],
      "metadata": {
        "id": "heIuoidrPPdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Zip File to local machine"
      ],
      "metadata": {
        "id": "AfdkU6lXffLi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "1dNA63JJj8Zp",
        "outputId": "c96e19e9-092f-451c-f56c-100d8d7eb71d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shutil' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a3078f4f0dab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test_whole_GME\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/TestImage\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
          ]
        }
      ],
      "source": [
        "shutil.make_archive(\"Test_whole_GME\", 'zip', \"/content/TestImage\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"Test_whole_GME.zip\")\n"
      ],
      "metadata": {
        "id": "weZi-bH4I4Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version2\n",
        "Add layers"
      ],
      "metadata": {
        "id": "XhCKSRvFk8X-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTlk_fKwACqh"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ConvLSTM_2(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters:\n",
        "        input_dim: Number of channels in input\n",
        "        hidden_dim: Number of hidden channels\n",
        "        kernel_size: Size of kernel in convolutions\n",
        "        num_layers: Number of LSTM layers stacked on each other\n",
        "        batch_first: Whether or not dimension 0 is the batch or not\n",
        "        bias: Bias or no bias in Convolution\n",
        "        return_all_layers: Return the list of computations for all layers\n",
        "        Note: Will do same padding.\n",
        "\n",
        "    Input:\n",
        "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
        "    Output:\n",
        "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
        "            0 - layer_output_list is the list of lists of length T of each output\n",
        "            1 - last_state_list is the list of last states\n",
        "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
        "    Example:\n",
        "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
        "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
        "        >> _, last_states = convlstm(x)\n",
        "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim=1,\n",
        "        hidden_dim=[16, 8, 8, 1],\n",
        "        kernel_size=[5, 3, 3, 3],\n",
        "        num_layers=4,\n",
        "        batch_first=True,\n",
        "        bias=True,\n",
        "        return_all_layers=True,\n",
        "    ):\n",
        "        super(ConvLSTM_2, self).__init__()\n",
        "\n",
        "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
        "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
        "            raise ValueError(\"Inconsistent list length.\")\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        self.bias = bias\n",
        "        self.return_all_layers = return_all_layers\n",
        "\n",
        "        # Add and initialize parameters\n",
        "        self.time_embedding = nn.Parameter(\n",
        "            torch.zeros(50, 1, 366, 366), requires_grad=True\n",
        "        )\n",
        "\n",
        "        cell_list = []\n",
        "        for i in range(0, self.num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
        "\n",
        "            cell_list.append(\n",
        "                ConvLSTMCell(\n",
        "                    input_dim=cur_input_dim,\n",
        "                    hidden_dim=self.hidden_dim[i],\n",
        "                    kernel_size=self.kernel_size[i],\n",
        "                    bias=self.bias,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.cell_list = nn.ModuleList(cell_list)\n",
        "\n",
        "    def forward(self, input_tensor, times, hidden_state=None):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor: todo\n",
        "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
        "        hidden_state: todo\n",
        "            None. todo implement stateful\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        last_state_list, layer_output\n",
        "        \"\"\"\n",
        "        if not self.batch_first:\n",
        "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
        "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        b, _, _, h, w = input_tensor.size()\n",
        "\n",
        "        # Implement stateful ConvLSTM\n",
        "        if hidden_state is not None:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            # Since the init is done in forward. Can send image size here\n",
        "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
        "\n",
        "        layer_output_list = []\n",
        "        last_state_list = []\n",
        "\n",
        "        seq_len = input_tensor.size(1)\n",
        "        cur_layer_input = (\n",
        "            input_tensor + self.time_embedding[times[:, : input_tensor.size(1)]]\n",
        "        )\n",
        "\n",
        "        for layer_idx in range(self.num_layers):\n",
        "            h, c = hidden_state[layer_idx]\n",
        "            output_inner = []\n",
        "            for t in range(seq_len):\n",
        "                h, c = self.cell_list[layer_idx](\n",
        "                    input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c]\n",
        "                )\n",
        "                output_inner.append(h)\n",
        "\n",
        "            layer_output = torch.stack(output_inner, dim=1)\n",
        "            cur_layer_input = layer_output\n",
        "\n",
        "            layer_output_list.append(layer_output)\n",
        "            last_state_list.append([h, c])\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            layer_output_list = layer_output_list[-1:]\n",
        "            last_state_list = last_state_list[-1:]\n",
        "\n",
        "        return layer_output_list, last_state_list\n",
        "\n",
        "    def _init_hidden(self, batch_size, image_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
        "        return init_states"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "model = ConvLSTM_2()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)"
      ],
      "metadata": {
        "id": "Hz4QeB4vy37Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsXtsJGF1dZw",
        "outputId": "5c2542e1-21fa-4296-9d63-6ab216f0c88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvLSTM_2(\n",
              "  (cell_list): ModuleList(\n",
              "    (0): ConvLSTMCell(\n",
              "      (conv): Conv2d(17, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    )\n",
              "    (1): ConvLSTMCell(\n",
              "      (conv): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (2): ConvLSTMCell(\n",
              "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (3): ConvLSTMCell(\n",
              "      (conv): Conv2d(9, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch_loss = float(\"inf\")\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    with tqdm(\n",
        "        enumerate(dataloader),\n",
        "        total=len(dataloader),\n",
        "        desc=f\"Epoch {epoch + 1}/{num_epochs}\",\n",
        "    ) as tepoch:\n",
        "        for i, (input_sequences, target_sequences, times) in tepoch:\n",
        "            input_sequences = input_sequences.to(device)\n",
        "            target_sequences = target_sequences.to(device)\n",
        "            times = times.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward\n",
        "            layer_output_list, _ = model(input_sequences, times)\n",
        "            output_sequences = layer_output_list[-1][\n",
        "                :, -target_sequences.size(1) :\n",
        "            ]  # Get the output of the last layer\n",
        "\n",
        "            # calculate loss\n",
        "            loss = criterion(output_sequences, target_sequences)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # backward and optimizer\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the progress bar\n",
        "            tepoch.set_postfix(loss=epoch_loss / (i + 1))\n",
        "\n",
        "    average_epoch_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Average Loss for Epoch {epoch + 1}: {average_epoch_loss:.4f}\")\n",
        "\n",
        "    # Check if it is the best model\n",
        "    if average_epoch_loss < best_epoch_loss:\n",
        "        best_epoch_loss = average_epoch_loss\n",
        "        # save model\n",
        "        torch.save(model.state_dict(), \"add_layer_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS-VZ-mX0gnw",
        "outputId": "d5e3e55d-8d9f-416e-d531-fdf9e6e62474"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 1161/1161 [20:45<00:00,  1.07s/it, loss=0.0168]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 1: 0.0168\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 1161/1161 [19:45<00:00,  1.02s/it, loss=0.0132]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 2: 0.0132\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 1161/1161 [19:46<00:00,  1.02s/it, loss=0.0128]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 3: 0.0128\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 1161/1161 [19:46<00:00,  1.02s/it, loss=0.0124]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 4: 0.0124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 1161/1161 [19:46<00:00,  1.02s/it, loss=0.0122]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 5: 0.0122\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 1161/1161 [19:46<00:00,  1.02s/it, loss=0.0121]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 6: 0.0121\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 1161/1161 [19:45<00:00,  1.02s/it, loss=0.012]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 7: 0.0120\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 1161/1161 [19:45<00:00,  1.02s/it, loss=0.0119]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 8: 0.0119\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 1161/1161 [19:46<00:00,  1.02s/it, loss=0.0118]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss for Epoch 9: 0.0118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 1161/1161 [19:46<00:00,  1.02s/it, loss=0.0118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss for Epoch 10: 0.0118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save predicted images\n",
        "\n",
        "subfolder = os.listdir(data_folder)\n",
        "create_or_clear_folder(\"Result2\")\n",
        "for fol in subfolder:\n",
        "    now_sample = []\n",
        "    wind_folder = os.path.join(data_folder, fol)\n",
        "    useful_data = list(\n",
        "        set([f[:7] for f in os.listdir(wind_folder) if f.startswith(fol)])\n",
        "    )\n",
        "    for name in useful_data:\n",
        "        image_path = os.path.join(wind_folder, name + \".jpg\")\n",
        "        json_path = os.path.join(wind_folder, name + \"_features.json\")\n",
        "        time = eval(json.load(open(json_path, \"r\"))[\"relative_time\"])\n",
        "        now_sample.append((image_path, time))\n",
        "    now_sample.sort(key=lambda x: x[1])\n",
        "\n",
        "    inp_image = []\n",
        "    inp_time = []\n",
        "    time_start = now_sample[-6][1]\n",
        "    for imgpath, time in now_sample[-6:]:\n",
        "        image = Image.open(imgpath).convert(\"L\")\n",
        "        image = transform(image)\n",
        "        inp_image.append(image)\n",
        "\n",
        "        time_id = (time - time_start) // 1000\n",
        "        if time_id > 49:\n",
        "            time_id = 49\n",
        "        elif time_id < 0:\n",
        "            time_id = 0\n",
        "        inp_time.append(time_id)\n",
        "        time_start = time\n",
        "    sequence_images = torch.stack(inp_image).to(device).unsqueeze(0)\n",
        "    times = torch.LongTensor(inp_time).to(device).unsqueeze(0)\n",
        "    layer_output_list, _ = model(sequence_images, times)\n",
        "    output_sequences = layer_output_list[-1][0, -3:].detach().cpu()  # The output of the last layer\n",
        "    create_or_clear_folder(os.path.join(\"Result2\", fol))\n",
        "    for i, img in enumerate(output_sequences):\n",
        "        img = img.clamp(0, 1)\n",
        "\n",
        "        # Convert Tensor to PIL image\n",
        "        img = TF.to_pil_image(img)\n",
        "        #\n",
        "        img.save(os.path.join(\"Result2\", fol, \"{}.jpg\".format(i + 1)))"
      ],
      "metadata": {
        "id": "twwq85pSDkc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Someting need to do\n",
        "\n",
        "\n",
        "1.   To adjust hyperparameters, try changing lr,bs,epoch....\n",
        "2.   Tweaking code structure design -pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "I0UOKju-nXSM"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}